,Train_Acc,Train_Loss,Test_Acc,Test_Loss,AUC,TN,FP,FN,TP,Accuracy,Precision,Recall,Specificity,FPR
0,89.48230147361755,0.10846958664069176,89.55897816539866,0.104093544857113,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
1,89.48230147361755,0.0925843758071106,89.55897816539866,0.09181415328623314,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
2,89.48230147361755,0.08992194035041343,89.55897816539866,0.08913702078674339,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
3,89.48230147361755,0.08969510098378812,89.55897816539866,0.08895905749158019,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
4,89.48230147361755,0.08965158820048395,89.55897816539866,0.08892354761276483,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
5,89.48230147361755,0.08962694708622923,89.55897816539866,0.08890764000249829,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
6,89.48230147361755,0.08960813257582305,89.55897816539866,0.08889558055782124,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
7,89.48230147361755,0.08960503676837107,89.55897816539866,0.08888743257912894,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
8,89.48230147361755,0.08959806296430052,89.55897816539866,0.08888124701869272,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
9,89.48230147361755,0.0895945366861265,89.55897816539866,0.0888758536566271,0.5,130311.0,0.0,15192.0,0.0,0.8955897816539865,,0.0,1.0,0.0
